{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f8df75d7-d1ca-4c65-aa2b-6f0392475608",
      "metadata": {
        "id": "f8df75d7-d1ca-4c65-aa2b-6f0392475608"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6699c17-162e-4962-b74a-2aa374cff77f",
      "metadata": {
        "id": "b6699c17-162e-4962-b74a-2aa374cff77f"
      },
      "source": [
        "## Workshop Day 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44dcc729-0f7a-466b-839d-e11f177e64b8",
      "metadata": {
        "id": "44dcc729-0f7a-466b-839d-e11f177e64b8",
        "jupyter": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# Dependencies (pay attention to tf version)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from util import *\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "print(tf.__version__)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bbd0226-c32a-407e-a6ab-d1c5243b7f9d",
      "metadata": {
        "id": "9bbd0226-c32a-407e-a6ab-d1c5243b7f9d"
      },
      "source": [
        "# Part 1: Extract data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa0f9c3-3cd7-49dc-b7c3-7382701560a9",
      "metadata": {
        "id": "0aa0f9c3-3cd7-49dc-b7c3-7382701560a9"
      },
      "source": [
        "Extract data of person walking with exoskeleton.\n",
        "For the purpose of this second experiment we will only observe Walking (both in transparent mode and in State Machine mode).\n",
        "\n",
        "We create two different df, one for SM one for transparent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1406925-de70-40e4-abca-7b24a83f340f",
      "metadata": {
        "id": "c1406925-de70-40e4-abca-7b24a83f340f",
        "jupyter": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "df_list = []\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "for filename in os.listdir(\"../data/\"):\n",
        "    if filename.endswith('_ml_dataset_extracted.csv'):\n",
        "        # Construct full file path\n",
        "        file_path = os.path.join(\"../data/\", filename)\n",
        "        # Read CSV file into DataFrame\n",
        "        df = pd.read_csv(file_path, index_col=0)\n",
        "        # Append DataFrame to list\n",
        "        df_list.append(df)\n",
        "\n",
        "# Concatenate all DataFrames in the list\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "df_Transparent = df[(df['condition'] == 'transparent_WALKING')& df.step_complete_r]\n",
        "df_StateMachine = df[(df['condition'] == 'SM_WALKING') & df.step_complete_r]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98cf7921",
      "metadata": {},
      "source": [
        "This time we don't interpolate the input and we also return as output the gait phase [0, 100]. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70943aff",
      "metadata": {
        "id": "70943aff"
      },
      "outputs": [],
      "source": [
        "def segment_stride(stance_interpolate_factor, joint, segment_length=100):\n",
        "    \"\"\"\n",
        "    Segments gait using stance interpolation factor\n",
        "\n",
        "    \"\"\"\n",
        "    segments_alpha = []\n",
        "    segments_theta = []\n",
        "    start_index = 0\n",
        "    completed_gait = False\n",
        "\n",
        "    for i in range(1, len(stance_interpolate_factor)):\n",
        "        if stance_interpolate_factor[i] == 1:\n",
        "            completed_gait = True\n",
        "        elif completed_gait and stance_interpolate_factor[i] == 0:\n",
        "            segments_alpha.append(stance_interpolate_factor[start_index:i])\n",
        "            segments_theta.append(joint[start_index:i])\n",
        "            start_index = i\n",
        "            completed_gait = False\n",
        "\n",
        "\n",
        "    gait_phases =[]\n",
        "    segments_alpha_2 = []\n",
        "    segments_theta_2 = []\n",
        "    for segment_al, segment_th in zip(segments_alpha, segments_theta):\n",
        "        x = np.linspace(0, 100, len(segment_al))\n",
        "        gait_phases.append(x)\n",
        "        segments_alpha_2.append(segment_al)\n",
        "        segments_theta_2.append(segment_th)\n",
        "\n",
        "    return segments_alpha_2, segments_theta_2, gait_phases\n",
        "\n",
        "\n",
        "# transparent\n",
        "segmented_joints_transparent ={0:[], 1: [], 2:[], 3:[]}\n",
        "segmented_velocity_transparent ={0:[], 1: [], 2:[], 3:[]}\n",
        "segmented_joints_SM= {0:[], 1: [], 2:[], 3:[]}\n",
        "segmented_velocity_SM= {0:[], 1: [], 2:[], 3:[]}\n",
        "for i in range(4):\n",
        "    segmented_alpha_transparent, segmented_joints_transparent[i], gait_phase_transparent = segment_stride( df_Transparent[' StanceInterpolationFactor'].to_numpy(), df_Transparent[' JointPositions_'+str(i+1)].to_numpy())\n",
        "    _, segmented_velocity_transparent[i], _ = segment_stride( df_Transparent[' StanceInterpolationFactor'].to_numpy(), df_Transparent[' JointVelocities_'+str(i+1)].to_numpy())\n",
        "    \n",
        "    segmented_alpha_SM, segmented_joints_SM[i], gait_phase_SM = segment_stride(df_StateMachine[' StanceInterpolationFactor'].to_numpy(), df_StateMachine[' JointPositions_'+str(i+1)].to_numpy())\n",
        "    _, segmented_velocity_SM[i], _ = segment_stride(df_StateMachine[' StanceInterpolationFactor'].to_numpy(), df_StateMachine[' JointVelocities_'+str(i+1)].to_numpy())\n",
        "\n",
        "N_STEPS_TRANSPARENT = len(segmented_alpha_transparent)\n",
        "N_STEPS_SM = len(segmented_alpha_SM)\n",
        "print(\"Number steps in transparent:\",N_STEPS_TRANSPARENT, \"Number steps in SM: \", N_STEPS_SM)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5b49ecc",
      "metadata": {
        "id": "f5b49ecc"
      },
      "source": [
        "Concatenate all steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "006234ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "006234ca",
        "outputId": "13a33d66-790f-499b-b7a4-bdb529dff553"
      },
      "outputs": [],
      "source": [
        "segmented_alpha_transparent = np.concatenate(segmented_alpha_transparent)\n",
        "gait_phase_transparent = np.concatenate(gait_phase_transparent)\n",
        "segmented_alpha_SM = np.concatenate(segmented_alpha_SM)\n",
        "gait_phase_SM = np.concatenate(gait_phase_SM)\n",
        "\n",
        "for i in range(4):\n",
        "      segmented_joints_transparent[i] = np.concatenate(segmented_joints_transparent[i])\n",
        "      segmented_velocity_transparent[i] = np.concatenate(segmented_velocity_transparent[i])\n",
        "      segmented_joints_SM[i] = np.concatenate(segmented_joints_SM[i])\n",
        "      segmented_velocity_SM[i] = np.concatenate(segmented_velocity_SM[i])\n",
        "\n",
        "print(segmented_alpha_transparent.shape, segmented_joints_transparent[0].shape, segmented_joints_transparent[1].shape, segmented_joints_transparent[2].shape,\n",
        "      segmented_joints_transparent[3].shape, gait_phase_transparent.shape)\n",
        "print(segmented_alpha_SM.shape, segmented_joints_SM[0].shape, segmented_joints_SM[1].shape,\n",
        "      segmented_joints_SM[2].shape, segmented_joints_SM[3].shape, gait_phase_SM.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f057743e",
      "metadata": {
        "id": "f057743e"
      },
      "source": [
        "Plot steps (with mean and variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d09943",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "c5d09943",
        "outputId": "5cec75c6-45b9-44b1-9170-8d6a415870bd"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(4, figsize=(10, 8))\n",
        "axs[0].set_title('Left Hip')\n",
        "axs[1].set_title('Left Knee')\n",
        "axs[2].set_title('Right hip')\n",
        "axs[3].set_title('Right knee')\n",
        "\n",
        "#transparent\n",
        "for i in range(4):\n",
        "    axs[i].plot(np.linspace(0, 100, 10000), (segmented_joints_transparent[i][:10000])*180/np.pi, 'g-', label= \"Transparent\")\n",
        "    axs[i].plot(np.linspace(0, 100, 10000),  segmented_alpha_transparent[:10000]*20, 'r-')\n",
        "    axs[i].plot(np.linspace(0, 100, 10000), gait_phase_transparent[:10000]/4, 'm-', label = \"Gait Phase Transparent\")\n",
        "\n",
        "    # STate machine\n",
        "    axs[i].plot(np.linspace(0, 100, 10000), segmented_joints_SM[i][:10000]*180/np.pi, 'b-', label= \"State Machine\")\n",
        "    axs[i].plot(np.linspace(0, 100, 10000), segmented_alpha_transparent[:10000]*20, 'r-')\n",
        "    axs[i].plot(np.linspace(0, 100, 10000), gait_phase_SM[:10000]/4, 'y-', label = \"Gait Phase SM\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfa2c9b",
      "metadata": {
        "id": "5cfa2c9b"
      },
      "source": [
        "# Part 2: Regression of the gait phase\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be54b54d",
      "metadata": {
        "id": "be54b54d"
      },
      "source": [
        "**Exercice 2** Build Neural Network that receives as input the kinematics and the stance interpolation factor and returns as output the gait phase (x coordidinate previous plot)\n",
        "\n",
        "We will build two models: one trained using transparent data, one using SM data and we will compare their performance on two validation sets (one SM one transparent). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b06757",
      "metadata": {
        "id": "d8b06757"
      },
      "source": [
        "### Prepare Input / output data\n",
        "\n",
        "<div>\n",
        "<img src=\"imgs/data_CNN.jpg\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "**Inputs:** The model had a data input size of 10 channel values (joint position/velocity) for every time step of 5 ms with a window size of 80 data samples. \n",
        "\n",
        "**Exercice** All input and output data is normalized (subtract mean and divide by std). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adbe6575",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adbe6575",
        "outputId": "3a997149-1e5c-4dfa-bf09-94ae25868ba7"
      },
      "outputs": [],
      "source": [
        "# concatenate joint angles and steps\n",
        "input_transparent= np.array([segmented_joints_transparent[0],\n",
        "                    segmented_joints_transparent[1],\n",
        "                    segmented_joints_transparent[2],\n",
        "                    segmented_joints_transparent[3]])\n",
        "# concatenate to input the joint velocity\n",
        "joint_velocity = np.array([segmented_velocity_transparent[0],\n",
        "                    segmented_velocity_transparent[1],\n",
        "                    segmented_velocity_transparent[2],\n",
        "                    segmented_velocity_transparent[3]])\n",
        "input_transparent = np.concatenate((input_transparent, joint_velocity, [segmented_alpha_transparent]), 0)\n",
        "\n",
        "# normalize input data\n",
        "mean= np.mean(input_transparent, 1)[:, np.newaxis]\n",
        "std = np.std(input_transparent, 1)[:, np.newaxis]\n",
        "input_transparent= (input_transparent ## TODO##\n",
        "print(\"Transparent\")\n",
        "print(\"Input Shape \", input_transparent.shape)\n",
        "print(\"input mean: \", mean.transpose())\n",
        "print(\"input std: \", std.transpose())\n",
        "\n",
        "# concatenate joint angles and steps\n",
        "input_SM= np.array([segmented_joints_SM[0],\n",
        "                    segmented_joints_SM[1],\n",
        "                    segmented_joints_SM[2],\n",
        "                    segmented_joints_SM[3]])\n",
        "# concatenate to input the joint velocity\n",
        "joint_velocity = np.array([segmented_velocity_SM[0],\n",
        "                    segmented_velocity_SM[1],\n",
        "                    segmented_velocity_SM[2],\n",
        "                    segmented_velocity_SM[3]])\n",
        "input_SM = np.concatenate((input_SM, joint_velocity, [segmented_alpha_SM]), 0)\n",
        "\n",
        "# normalize input data\n",
        "mean= np.mean(input_SM, 1)[:, np.newaxis]\n",
        "std = np.std(input_SM, 1)[:, np.newaxis]\n",
        "input_SM= (input_SM ## TODO ##\n",
        "print(\"State Machine\")\n",
        "print(\"Input Shape \", input_SM.shape)\n",
        "print(\"input mean: \", mean.transpose())\n",
        "print(\"input std: \", std.transpose())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4e16b52",
      "metadata": {
        "id": "a4e16b52"
      },
      "source": [
        "Prepare Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f47f5bc4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f47f5bc4",
        "outputId": "446f8aeb-5a1c-4588-bcc8-9ca5ff1df06f"
      },
      "outputs": [],
      "source": [
        "output_transparent = np.array(gait_phase_transparent)/100.0 # created normalized\n",
        "print(\"Output transparent shape \", output_transparent.shape)\n",
        "\n",
        "output_SM = gait_phase_SM/100.0 # created normalized\n",
        "print(\"Output SM shape \", output_SM.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6993fa3f",
      "metadata": {
        "id": "6993fa3f"
      },
      "source": [
        "Divide data in time windows: save one value every 5ms, since data is recorded with a frequency of 333Hz the data must be reshaped to have a frequency of 200Hz\n",
        "\n",
        "**EX:** Change the size of data to adapt it to the size of the new frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde09b5c",
      "metadata": {
        "id": "dde09b5c"
      },
      "outputs": [],
      "source": [
        "import scipy.signal as signal\n",
        "\n",
        "def divide_time_windows(input, output, window_length, step):\n",
        "    divided_input = []\n",
        "    divided_output = []\n",
        "\n",
        "    # downsampling\n",
        "    ORIGINAL_FREQUENCY = 333 #Hz\n",
        "    DESIRED_FREQUENCY = 200\n",
        "    num_samples = int(input.shape[1] ## TODO###\n",
        "\n",
        "    input = signal.resample(input, num_samples, axis=1)\n",
        "    output = signal.resample(output, num_samples)\n",
        "    output[output > 1] = 1\n",
        "    output[output < 0] = 0\n",
        "\n",
        "    # divide in window\n",
        "    for i in range(window_length, input.shape[1], step):\n",
        "        divided_input.append(input[:, i-window_length: i])\n",
        "        divided_output.append(output[i])\n",
        "\n",
        "    return np.array(divided_input), np.array(divided_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da173e3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da173e3f",
        "outputId": "e7a436a0-e724-4bdf-b333-afc39682df1f"
      },
      "outputs": [],
      "source": [
        "WINDOW_LENGTH = 80 #check frequency\n",
        "STEP = 3\n",
        "input_transparent, output_transparent = divide_time_windows(input_transparent, output_transparent, WINDOW_LENGTH, STEP)\n",
        "print(\"Data transparent Shape: \", input_transparent.shape, output_transparent.shape)\n",
        "\n",
        "input_SM, output_SM = divide_time_windows(input_SM, output_SM, WINDOW_LENGTH, STEP)\n",
        "print(\"Data SM Shape: \", input_SM.shape, output_SM.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c8dd0f",
      "metadata": {
        "id": "82c8dd0f"
      },
      "source": [
        "Divide training set and output set in training and validation set (70%, 30%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c77de913",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77de913",
        "outputId": "d0ce3ec3-5b31-4136-a96f-be86d18c54ab"
      },
      "outputs": [],
      "source": [
        "train_input_transparent = np.swapaxes(input_transparent[:int(input_transparent.shape[0]*0.7), :, :], 1, 2)\n",
        "train_output_transparent = output_transparent[:int(input_transparent.shape[0]*0.7)]\n",
        "val_input_transparent =  np.swapaxes(input_transparent[int(input_transparent.shape[0]*0.7):, :, :], 1, 2)\n",
        "val_output_transparent = output_transparent[int(input_transparent.shape[0]*0.7):]\n",
        "\n",
        "print(\"Transparent \")\n",
        "print(\"Training set shape: \", train_input_transparent.shape, train_output_transparent.shape)\n",
        "print(\"Validation set shape: \", val_input_transparent.shape, val_output_transparent.shape)\n",
        "\n",
        "train_input_SM = np.swapaxes(input_SM[:int(input_SM.shape[0]*0.7), :, :], 1, 2)\n",
        "train_output_SM = output_SM[:int(input_SM.shape[0]*0.7)]\n",
        "val_input_SM =  np.swapaxes(input_SM[int(input_SM.shape[0]*0.7):, :, :], 1, 2)\n",
        "val_output_SM = output_SM[int(input_SM.shape[0]*0.7):]\n",
        "\n",
        "print(\"State Machine\")\n",
        "print(\"Training set shape: \", train_input_SM.shape, train_output_SM.shape)\n",
        "print(\"Validation set shape: \", val_input_SM.shape, val_output_SM.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f0efa82",
      "metadata": {
        "id": "8f0efa82"
      },
      "source": [
        "### Create Model:\n",
        "\n",
        "<div>\n",
        "<img src=\"imgs/models.jpg\" width=\"700\"/>\n",
        "</div>\n",
        "\n",
        "The model had a data input size of 9 channel values (left/right hip, knee position/velocity and alpha) for every time step of 5 ms with a window size of 80 data samples (80*9). The first layer consisted of a 1D convolution of 10 filters striding temporally, where each filter had a kernel size of 20. The third layer was another 1D convolution of 10 filters, where each filter had a kernel size of the previous layer’s window size and compressed the data into a single row vector (representing the extracted feature information). A sigmoid activation function was applied to this vector and passed the data to two fully connected dense layers with relu activation function (20 nodes the first 10 the second). The final dense layer of the network output two dimensions (to describe the periodic nature of the gait phase we represent the output as the sin and cos of the gait phase) and uses a tanh transfer function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bfe1b05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bfe1b05",
        "outputId": "c5be11ae-80b9-4cca-a71c-4c4fc2a72d06"
      },
      "outputs": [],
      "source": [
        "model_transparent = models.Sequential()\n",
        "model_transparent.add(layers.GaussianNoise(0.01, input_shape=(80,9)))\n",
        "model_transparent.add(layers.Conv1D(## TODO##\n",
        "model_transparent.add(layers.Conv1D(10, ## TODO, activation = 'sigmoid'))\n",
        "model_transparent.add(layers.Flatten())\n",
        "model_transparent.add(layers.Dense(## TODO ##\n",
        "model_transparent.add(## TODO ##\n",
        "model_transparent.add(layers.Dense(2, activation='tanh'))\n",
        "\n",
        "model_transparent.summary()\n",
        "\n",
        "model_SM = models.Sequential()\n",
        "model_SM.add(layers.GaussianNoise(0.01, input_shape=(80,9)))\n",
        "model_SM.add(layers.Conv1D(## TODO##\n",
        "model_SM.add(layers.Conv1D(10, ## TODO##, activation = 'sigmoid'))\n",
        "model_SM.add(layers.Flatten())\n",
        "model_SM.add(layers.Dense(## TODO##\n",
        "model_SM.add(## TODO##, activation = 'relu'))\n",
        "model_SM.add(layers.Dense(2, activation=## TODO##))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84559b5d",
      "metadata": {
        "id": "84559b5d"
      },
      "source": [
        "**Loss function:** To ensure that the gait phase error was evaluated accurately during the transition from one gait cycle to the next, where 100 and 0 represent the same value, we used an angular similarity metric by computing the cosine and sin of the sine of the gait phase and we compared it the predicted two outputs. The root mean square error (RMSE) of was computed between them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f402cc",
      "metadata": {
        "id": "96f402cc"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "    gait_phase_cos_error =## TODO##(tf.reduce_mean(tf.square(y_pred[:, 0] - tf.## TODO ##(y_true*2*np.pi))))\n",
        "    gait_phase_sin_error = tf.sqrt(tf.reduce_mean(tf.square(## TODO## - ## TODO ##)))\n",
        "    return gait_phase_cos_error + gait_phase_sin_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d177be06",
      "metadata": {
        "id": "d177be06"
      },
      "source": [
        "### Train the two models\n",
        "\n",
        "**Training:** The CNN was trained for 15 epochs using a Adam optimizer with a learning rate of 0.001 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "600716fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "600716fc",
        "outputId": "36217ab4-56f2-4cde-a0c3-de7f643fc49e"
      },
      "outputs": [],
      "source": [
        "optimizer_transparent = tf.keras.optimizers.Adam(learning_rate=## TODO##)\n",
        "\n",
        "model_transparent.compile(loss=loss_function,\n",
        "          optimizer=optimizer_transparent,\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "history = model_transparent.fit(train_input_transparent, train_output_transparent, epochs=## TODO##,\n",
        "                    validation_data=(val_input_transparent, val_output_transparent))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a8bf7a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a8bf7a2",
        "outputId": "c35d2576-7c41-4571-82fb-f2189bee2129"
      },
      "outputs": [],
      "source": [
        "optimizer_SM = tf.keras.optimizers.Adam(learning_rate=## TODO##)\n",
        "\n",
        "model_SM.compile(loss=loss_function,\n",
        "          optimizer=optimizer_SM,\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "history = model_SM.fit(train_input_SM, train_output_SM, epochs=## TODO##,\n",
        "                    validation_data=(val_input_SM, val_output_SM))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e78e0766",
      "metadata": {},
      "source": [
        "### Validation models\n",
        "\n",
        "Validate the two models with the two validation sets to evaluate the generalization ability, 4 combinations:\n",
        "- Model trained with transparent data <--> tested on transparent data\n",
        "- Model trained with transparent data <--> tested on SM data\n",
        "- Model trained with SM data <--> tested on transparent data\n",
        "- Model trained with SM data <--> tested on SM data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b4b97f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00b4b97f",
        "outputId": "9f486cfa-5635-40b8-9294-5a6dd4aee25e"
      },
      "outputs": [],
      "source": [
        "y_pred_trans_trans = model_transparent.predict(val_input_transparent)\n",
        "y_pred_trans_SM = model_transparent.predict(val_input_SM)\n",
        "y_pred_SM_SM = model_SM.predict(val_input_SM)\n",
        "y_pred_SM_trans = model_SM.predict(val_input_transparent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf7b12b",
      "metadata": {},
      "source": [
        "**Exercice** Create a function that given the output in (cos, sin) transform it in the gait phase: $$arctan(2\\pi cos / 2\\pi sin)mod(2\\pi)/2\\pi$$. \n",
        "\n",
        "Function np.arctan2 takes as input (sin, cos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "569f2d54",
      "metadata": {
        "id": "569f2d54"
      },
      "outputs": [],
      "source": [
        "def transform_output(y_pred):\n",
        "    cos = y_pred[:, 0]\n",
        "    sin = y_pred[:, 1]\n",
        "    return (np.arctan2(## TODO ##, ## TODO ##) % (## TODO ##)) /(## TODO ##)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def099c0",
      "metadata": {},
      "source": [
        "Visualize the output of the two models trying to predicting the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7123a8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "c7123a8b",
        "outputId": "2ee82801-b394-455d-b4c6-ba459e09e664"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, axs = plt.subplots(2, figsize=(10, 8))\n",
        "axs[0].plot(transform_output(y_pred_trans_trans[:2000]), color=\"b\",  label = \"Trans model prediction\")\n",
        "axs[0].plot(transform_output(y_pred_SM_trans[:2000]), color=\"g\", label = \"SM model prediction\")\n",
        "axs[0].plot(val_output_transparent[:2000], color='r', label=\"Transparent gt data\")\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(transform_output(y_pred_trans_SM[:2000]), color= \"b\", label = \"Trans model prediction\")\n",
        "axs[1].plot(transform_output(y_pred_SM_SM[:2000]), color =\"g\", label = \"SM model prediction\")\n",
        "axs[1].plot(val_output_SM[:2000], color='r',  label=\"SM gt data\")\n",
        "\n",
        "axs[1].legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8af5026f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "8af5026f",
        "outputId": "33145a5f-88f0-4641-db92-298985ba6056"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "trans_trans_error = np.sqrt(np.mean(np.square(transform_output(y_pred_trans_trans) - val_output_transparent)))\n",
        "trans_SM_error = np.sqrt(np.mean(np.square(transform_output(y_pred_trans_SM) - val_output_SM)))\n",
        "SM_trans_error = np.sqrt(np.mean(np.square(transform_output(y_pred_SM_trans) - val_output_transparent)))\n",
        "SM_SM_error = np.sqrt(np.mean(np.square(transform_output(y_pred_SM_SM) - val_output_SM)))\n",
        "\n",
        "confusion_matrix = np.array([[trans_trans_error, trans_SM_error],\n",
        "                             [SM_trans_error, SM_SM_error]])\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[\"transp\", \"SM\"])\n",
        "disp.plot(ax=ax, cmap='viridis')\n",
        "plt.xlabel('Validation data')\n",
        "plt.ylabel('Training data')\n",
        "plt.title(\"Regression loss depending by model and data\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4196136f",
      "metadata": {},
      "source": [
        "Discuss with the rest of the group what this performances means. In particular, the values at the top-right and botton-left."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b52aa7",
      "metadata": {
        "id": "b7b52aa7"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FQqTGhmKMsMf",
      "metadata": {
        "id": "FQqTGhmKMsMf"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "model_transparent.export(\"../models/transparent/\")\n",
        "model_SM.export(\"../models/SM/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8b86c3",
      "metadata": {},
      "source": [
        "Send the two created models as zip file with the following format: *transparent(SM)_groupNumber* at the following email adress: lvianello@sralab.org"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "038a90e1",
      "metadata": {},
      "source": [
        "# Part 3: Locomotion mode classification\n",
        "- transparent_WALKING, SM_WALKING --> 1\n",
        "- SM_RAMPS_DOWN, transparent_RAMPS_DOWN --> 3\n",
        "- SM_RAMPS_UP, transparent_RAMPS_UP --> 2\n",
        "- SM_STAIRS_UP, transparent_STAIRS_UP --> 4\n",
        "- SM_STAIRS_DOWN, transparent_STAIRS_DOWN --> 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c57e18ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_locomotion_modes = df[df.step_complete_r]\n",
        "print(np.unique(df_locomotion_modes['condition']))\n",
        "print(np.unique(df_locomotion_modes['condition_encoded']))\n",
        "CLASSES = [\"Walking\", \"Ramp\\nAsc\", \"Ramp\\nDesc\", \"Stairs\\nAsc\", \"Stair\\nDesc\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b6125ca",
      "metadata": {},
      "source": [
        "Plot conditions over time "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af261e1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(df_locomotion_modes['condition_encoded'], label = \"condition encoded\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acaef290",
      "metadata": {},
      "source": [
        "Prepare dataset (input same as before, joint position and velocity, stance interpol), output the 5 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb38228",
      "metadata": {},
      "outputs": [],
      "source": [
        "# concatenate joint angles and steps\n",
        "joint_position_lm= np.array([df_locomotion_modes[' JointPositions_1'],\n",
        "                    df_locomotion_modes[' JointPositions_2'],\n",
        "                    df_locomotion_modes[' JointPositions_3'],\n",
        "                    df_locomotion_modes[' JointPositions_4']])\n",
        "# concatenate to input the joint velocity\n",
        "joint_velocity_lm = np.array([df_locomotion_modes[' JointVelocities_1'],\n",
        "                    df_locomotion_modes[' JointVelocities_2'],\n",
        "                    df_locomotion_modes[' JointVelocities_3'],\n",
        "                    df_locomotion_modes[' JointVelocities_4']])\n",
        "input_lm = np.concatenate((joint_position_lm, joint_velocity_lm, [df_locomotion_modes[' StanceInterpolationFactor']]), 0)\n",
        "\n",
        "# normalize input data\n",
        "mean= np.mean(input_lm, 1)[:, np.newaxis]\n",
        "std = np.std(input_lm, 1)[:, np.newaxis]\n",
        "input_lm= (input_lm - mean) / std\n",
        "print(\"Input Shape \", input_lm.shape)\n",
        "print(\"input mean: \", mean.transpose())\n",
        "print(\"input std: \", std.transpose())\n",
        "\n",
        "output_lm = np.array(np.eye(5)[df_locomotion_modes['condition_encoded']- 1]) # created normalized and convert to categorical output\n",
        "print(\"Output locomotion mode classification shape \", output_lm.shape)\n",
        "\n",
        "\n",
        "WINDOW_LENGTH = 80 #check frequency\n",
        "STEP = 3\n",
        "input_lm, output_lm = divide_time_windows(input_lm, output_lm, WINDOW_LENGTH, STEP)\n",
        "print(\"Data Shape: \", input_lm.shape, output_lm.shape)\n",
        "\n",
        "\n",
        "train_input_lm = np.swapaxes(input_lm[:int(input_lm.shape[0]*0.7), :, :], 1, 2)\n",
        "train_output_lm = output_lm[:int(input_lm.shape[0]*0.7)]\n",
        "val_input_lm =  np.swapaxes(input_lm[int(input_lm.shape[0]*0.7):, :, :], 1, 2)\n",
        "val_output_lm = output_lm[int(input_lm.shape[0]*0.7):]\n",
        "\n",
        "print(\"Training set shape: \", train_input_lm.shape, train_output_lm.shape)\n",
        "print(\"Validation set shape: \", val_input_lm.shape, val_output_lm.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "309e80a3",
      "metadata": {},
      "source": [
        "**Exercice** Create the model (similar to the previous one but this time remember that the output must be categorical (value 0 or 1) and should have 5 dimensions), some suggestions:\n",
        "- suggested activation function :softmax\n",
        "- as loss function a common one is CategoricalCrossentropy (no need to design one by your self 'tf.keras.losses.CategoricalCrossentropy()')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e05dbaf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lm = models.Sequential()\n",
        "model_lm.add(##TODO##)\n",
        "##TODO##\n",
        "model_lm.add(layers.Dense(5, activation=##TODO##))\n",
        "\n",
        "#model_lm.summary()\n",
        "\n",
        "optimizer_lm = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model_lm.compile(loss=## TODO##,\n",
        "          optimizer=optimizer_lm,\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "history = model_lm.fit(train_input_lm, train_output_lm, epochs=15,\n",
        "                    validation_data=(val_input_lm, val_output_lm))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e33695",
      "metadata": {},
      "source": [
        "Predict validation set for evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53a52058",
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_values = model_lm.predict(val_input_lm)\n",
        "\n",
        "plt.plot(np.argmax(predicted_values, 1), label= \"Prediction\")\n",
        "plt.plot(np.argmax(val_output_lm, 1), label= \"GT\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e413cb",
      "metadata": {},
      "source": [
        "Plot prediction probability (between 0 and 1) and max values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa7902d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, figsize=(10, 8))\n",
        "\n",
        "axs[1].plot(predicted_values[:, 0], label= \"Walking prediction probability\")\n",
        "axs[1].plot(predicted_values[:, 1], label= \"Ramps Asc prediction probability\")\n",
        "axs[1].plot(predicted_values[:, 2], label= \"Ramps Desc prediction probability\")\n",
        "axs[1].plot(predicted_values[:, 3], label= \"Stair Asc prediction probability\")\n",
        "axs[1].plot(predicted_values[:, 4], label= \"Stair Desc prediction probability\")\n",
        "\n",
        "axs[0].plot(np.argmax(predicted_values, 1), label= \"Max value Prediction\")\n",
        "axs[0].plot(np.argmax(val_output_lm, 1), label= \"GT\")\n",
        "\n",
        "axs[0].legend()\n",
        "axs[1].legend()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638a08a9",
      "metadata": {},
      "source": [
        "Display confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d83939c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix = metrics.confusion_matrix(np.argmax(val_output_lm, 1), np.argmax(predicted_values, 1))\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = CLASSES)\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94cb6b85",
      "metadata": {},
      "source": [
        "# Part 4: Real time prediction using tensorflow lite"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
